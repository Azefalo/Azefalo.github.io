{
  "featured": "keyless-access-car",
  "items": [
    {
      "id": "keyless-access-car",
      "titulo": " ACTIA Keyless Access Car",
      "periodo": "Academic Year 2025-2026",
      "status": "In progress",
      "tecnologias": ["Python","NXP Boards", "UWB","BLE","IoT","AWS IoT Core", "MQTT", "Presentation"],
      "tags": ["Ultra Wideband","Energy Management", "Cloud Integration","Embedded Systems"],
      "imagens": ["assets/img/keyless.jpg","assets/img/NXP_board.jpg","assets/img/NXP_showroom.png"],
      "relatorio_pdf": "reports/keyless-access-car.pdf",
      "descricao": "This project prototypes a secure keyless-access solution for automotive fleets, where a corporate smartphone replaces physical keys while keeping strong proximity guarantees. The work was developed in collaboration with ACTIA and NXP, within an ECIU challenge and with an international team from Linköping University, targeting an industrial use case of scalable fleet access management.\n\nThe system combines BLE for discovery and authentication at longer range with UWB for centimeter-level ranging close to the vehicle, improving both usability and protection against proximity-based attacks. Beyond a basic demo, the project also adds cloud logging for traceability and an energy assessment to understand deployment limits in a real parked-vehicle scenario.",
      "tecnica": "The implemented workflow is entirely UWB-driven for the delivered prototype. The setup uses one initiator board (user side) and five in-vehicle anchors whose ranges are collected by a computer running a unified Python loop. At each cycle, the latest available distances are retrieved, time-stamped, and validated to handle missing or invalid values before any estimation step.\n\nPosition estimation is performed on the 2D vehicle plane using a triangulation-style approach where each distance defines a circle around an anchor, and the user position is computed as the best fit under noisy and often inconsistent constraints. The initial workflow evaluated localization in post-processing (distance logs first, trajectory reconstruction afterwards). To make the system testable during vehicle sessions, acquisition and localization were merged into a single real-time pipeline so that each new distance frame is immediately fed to the solver without manual intermediate steps.\n\nRobustness improvements were introduced because real UWB measurements suffer from multipath and non-line-of-sight effects, which can destabilize naive optimization. The positioning step was reformulated as a nonlinear least-squares estimation problem and paired with temporal continuity and filtering to produce smoother, physically plausible trajectories. Warm-starting from the previous state reduces sensitivity to initialization, while validation logic prevents corrupted samples from propagating into the estimator. A Kalman filtering stage then stabilizes the sequence of estimated positions over time.\n\nA live visualization was added to interpret behavior during experiments. Using matplotlib.animation, the interface updates every ranging cycle and displays the estimated user position, anchor locations, and recent trajectory history, making it easy to verify that acquisition, estimation, and publication are operating end-to-end.\n\nFor cloud integration, the real-time outputs are structured as a consistent MQTT payload that includes timestamps, anchor-labeled distances when available, and the computed localization outputs (estimated position and a proximity-oriented indicator). Messages are published to AWS IoT Core over TLS using X.509 authentication, then routed through AWS IoT Rules into DynamoDB for persistent storage as a spreadsheet-like time-series table that can be queried and reviewed after tests.",
      "sistema_de_curso": "The project was carried out across 14 work sessions of 2h45, starting with environment setup and hardware/software onboarding, then moving to parallel development in sub-teams (localization algorithms vs cloud integration) to improve productivity. In addition, 22 English sprint classes (1h15) supported agile planning and communication, and recurring progress meetings with an ACTIA representative helped keep the work aligned with an industrial roadmap and integration constraints.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Analyse a real-life problem"},
        {
          "nota": 4,
          "titulo": "Suggest a technological solution to a problem"},
        {
          "nota": 4,
          "titulo": "Implement a prototype to solve the problem"},
        {
          "nota": 4,
          "titulo": "Present and debate (in English) the technical choice made"},
        {
          "nota": 4,
          "titulo": "Produce a report (in English) for the developed project "}
      ],
      "justificativa": "All competencies were assessed at the highest level because the project covered the full engineering loop: an industrial problem was defined with ACTIA, a concrete UWB architecture was proposed, and an end-to-end prototype was implemented with measurable outcomes in localization quality, cloud traceability, and energy impact. The work required technical justification in English and resulted in a structured written report documenting design choices, experiments, and deployment constraints. I also improved my ability to discuss trade-offs with industry stakeholders and to deliver reliable results under real-world measurement noise.",
      "relacao_projeto_profissional": "This project directly matches roles in connected vehicles, embedded systems, and IoT security, where proximity verification, robust sensing pipelines, and secure device-to-cloud integration are central. The combination of UWB ranging, BLE workflows, MQTT security, and AWS-based persistence reflects modern industry stacks used in fleet management and digital-key ecosystems.\n\nIt also provided a clear differentiator for internships and interviews: hands-on experience with AWS IoT Core, certificate-based authentication, and database-backed experiment traceability is frequently requested in IoT positions. By building and validating this pipeline myself, the project strengthened my profile for embedded and cloud-connected systems in the automotive and aerospace ecosystem, where reliability, security, and energy budgeting are treated as first-class design requirements."
    },

    {
      "id": "smart-devices",
      "titulo": "Smart devices: from manufacturing to application",
      "github": "https://github.com/MOSH-Insa-Toulouse/2025-2026-5ISS-BENCHEKROUN-DIANI-AZZABI-BUTTOW-ELGHAIT",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Nanofabrication", "Arduino IDE", "C++", "LoRaWAN", "Node-RED", "PCB"],
      "tags": ["Smart devices", "Gas sensor", "IoT"],
      "imagens": ["assets/img/smart-devices.png", "assets/img/gas_sensor.jpeg", "assets/img/open_source.jpg"],
      "relatorio_pdf": "reports/smart_devices.pdf",
      "descricao": "This project aimed to build a complete IoT gas-sensor system from scratch. It started with nanofabrication of a WO₃-based metal-oxide gas sensor and concluded with a connected device that sends data over LoRaWAN and displays it on a custom dashboard. The work combined hands-on laboratory fabrication, sensor characterization, analog conditioning, embedded programming, wireless communication and software integration. By going through all stages, from microfabrication to cloud connectivity, the course provided a comprehensive view of how smart devices are created.\n\nThe full project documentation, including sensor datasheet, firmware, Node‑RED flows, PCB design files and a mobile app prototype, has been made open source on GitHub to support future learning and development in the community with the following link: https://github.com/MOSH-Insa-Toulouse/2025-2026-5ISS-BENCHEKROUN-DIANI-AZZABI-BUTTOW-ELGHAIT",
      "tecnica": "The core component was a metal-oxide gas sensor using tungsten trioxide nanoparticles deposited between interdigitated electrodes. Two identical sensing elements and an integrated polysilicon heater allowed control of the operating temperature up to about 300 °C, monitored by a metal thermistor. The sensor was packaged in a 10-lead TO-5 can and exhibited very high resistance in dry air (10–20 GΩ). Electrical characterization measured an aluminium thermistor resistance around 86 Ω at room temperature with ~1 Ω / °C sensitivity. Gas-response tests at 277 °C with 1000 ppm ethanol showed a relative resistance change of ~64 %, a sensitivity of 85 kΩ / ppm and a detection limit near 38 ppm. These results were compiled into a data sheet and informed the design of an analog front-end.\n\nBecause the sensor resistance is extremely high, a transimpedance amplifier with high gain was designed to convert nanoampere currents into measurable voltages for the Arduino ADC. RC filters reduced low-frequency drift and mains interference. Simulations confirmed an amplifier gain near 101 and effective suppression of 50 Hz noise. The microcontroller used was an Arduino Uno, chosen for its large community support and compatibility with the RN2483A LoRaWAN module. The firmware reads the gas sensor on analog pin A0, displays values on an OLED, triggers an LED alarm when the threshold is exceeded and transmits data via The Things Network every 10 s.\n\nFor remote connectivity, the system used LoRaWAN. Recent trends in LoRaWAN point to hybrid sub‑GHz + 2.4 GHz operation for higher data rates, stronger encryption and key-management schemes, and multi-hop relays that extend coverage without replacing gateways. Integrating such protocols ensured that the gas-sensor prototype is aligned with current IoT developments. On the software side, Node‑RED was employed to build an MQTT-based pipeline that subscribes to ChirpStack/TTN topics, decodes payloads, applies threshold logic and displays real-time and historical data on a dashboard.\n\nBeyond the prototype, a custom PCB was designed in KiCAD, integrating the sensor, amplifier, microcontroller, digital potentiometers and LoRa module into a single board. A basic mobile app was created with MIT App Inventor to control and monitor the system via Bluetooth, demonstrating how users could interact with the device.",
      "sistema_de_curso": "The course combined intensive laboratory work and classroom sessions. Approximately 20 hours were dedicated to nanofabrication, including photolithography, electrode patterning and nanoparticle deposition. Around 19 class sessions of 1h15 each covered sensor characterization, analog circuit design, simulation with LTSpice, programming the Arduino and integrating LoRaWAN and Node‑RED. Students developed a full data sheet, wrote firmware, built Node‑RED flows, designed the PCB and tested the system with instructors.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Understand microcontroller archictecture and how to use them"
        },
        {
          "nota": 4,
          "titulo": "Be able to design data acquisition system (sensor, conditioner, microcontroller) with respect to the application"
        },
        {
          "nota": 3,
          "titulo": "Be able to design a shield to accommodate the gas sensor"
        },
        {
          "nota": 4,
          "titulo": "Be abe to design the sofware to use the gas sensor and its HMI"
        },
        {
          "nota": 4,
          "titulo": "Be able to combine all of the above mentioned components into a smart device"
        },
        {
          "nota": 4,
          "titulo": "Be able to manufacture a nano-particles sensor using micro-electronics tools: chemical synthesis, assembly, testing"
        },
        {
          "nota": 4,
          "titulo": "Understand basic notions of sensors, data acquisition: physics, electronics and metrology point of view"
        },
        {
          "nota": 4,
          "titulo": "Be able to design the datasheet of the sensor manufactured"
        },
        {
          "nota": 4,
          "titulo": "Be able to design the electronic circuit of a sensor’s signal conditioner (design + simulation)"
        }
      ],
      "justificativa": "The competence scores reflect a project that spanned sensor fabrication, electronic design and IoT integration. Mastery of microcontroller architecture was required to code the Arduino and implement LoRaWAN communication. Designing the data-acquisition chain demanded understanding of high-impedance sensors and amplifier circuits. While the PCB concept was realized, the shield itself remained a work in progress, justifying a slightly lower score. Overall, the practical work enabled a deeper grasp of nanofabrication, sensor physics, analog conditioning and embedded software.",
      "relacao_projeto_profissional": "This project has direct relevance to my professional ambitions in embedded systems and IoT. Building a gas-sensor platform from the ground up required integrating nanoscale fabrication with system-level design, which echoes the multidisciplinary challenges in modern product development. By applying both analog and digital design skills, I feel better prepared to tackle future projects such as integrating camera-based AI sensors on STM microcontrollers with LoRaWAN connectivity. The experience of designing a custom PCB, coding network protocols and deploying a dashboard has strengthened my confidence to contribute to smart-city and industrial IoT solutions."
    },

    {
      "id": "embedded-ia-for-iot",
      "titulo": "Embedded IA for IoT - Fall Detection",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Python", "CNN","TensorFlow","Keras","NumPy"],
      "tags": ["Machine Learning","Computer Vision","Deep Learning"],
      "imagens": ["assets/img/projeto-ml.jpg", "assets/img/CNN.png"],
      "relatorio_pdf": "reports/video_ai.url",
      "descricao": "Embedded IA for IoT connected machine learning fundamentals to the practical constraints of running inference directly on edge devices. The core work revolved around fall detection for assisted living scenarios, framed as a real-time decision problem where sending images to a remote server is not acceptable due to latency, privacy, and robustness constraints.\n\nThe hands-on project applied computer vision on the CAUCAFall dataset (about 20,000 labeled images across multiple daily activities) to classify fall vs non-fall situations. I treated it as an end-to-end embedded AI exercise: build a baseline model that works, then make it small and efficient enough to run on constrained hardware without losing too much reliability.",
      "tecnica": "The course covered the full edge-AI pipeline: understanding data types used in IoT (tabular signals, time series, and images), preparing datasets for training, training and validating models, and then optimizing models for deployment under memory, compute, and energy constraints. Practical work emphasized not only “how to train”, but also how to reason about complexity, latency, and the impact of design choices when inference must happen locally at the edge.\n\nFor the fall-detection lab, the starting point was the CAUCAFall dataset, provided as labeled PNG images. A preprocessing pipeline was used to reduce background noise and focus the model on the person: a YOLO-based segmentation step extracted a square crop around the subject (roughly 200 to 350 pixels per side), then images were resized to 96 × 96 to control computational cost. Labels from multiple activities were merged into a binary target: fall vs non-fall, and the split was done by subject (training on subjects 1 to 8, testing on subjects 9 and 10) to check generalization to unseen people.\n\nA Convolutional Neural Network (CNN) was chosen because images have strong spatial structure. Convolution layers learn local filters that detect simple patterns early (edges, intensity transitions) and progressively build higher-level features later (body parts, posture configurations). Pooling reduces spatial resolution while keeping the most salient activations, improving robustness to small translations or viewpoint changes and reducing computation. The final classifier layers combine the extracted features to output the fall vs non-fall decision.\n\nTraining followed a standard supervised workflow in Python notebooks: dataset loading, normalization and reshaping, train/validation strategy for hyperparameter choices (architecture depth, number of filters, learning rate, stopping criteria), and evaluation using accuracy plus confusion-matrix analysis to understand false alarms vs missed falls. This evaluation perspective was important because a “good accuracy” can still hide unsafe behavior if the error distribution is not acceptable for the application.\n\nThe embedded constraint was treated as a first-class requirement. Edge inference must react quickly and cannot depend on cloud connectivity, which forces tight control of model size, RAM usage, and compute cost. The target platform introduced in the course was the Coral Dev Board Micro, which integrates a camera and the Coral Edge TPU accelerator, but requires integer quantized models for efficient execution.\n\nModel compression was the key technical theme to bridge “works on a laptop” to “runs on embedded hardware”:\n(I.) Pruning reduced the number of effective connections by removing weights with very small magnitude. This decreases model complexity and memory footprint, and in some cases can slightly improve generalization by removing weights that mostly learn noise. Multiple sparsity levels were explored to find a workable trade-off between size reduction and detection reliability.\n(II.) Quantization converted weights and activations from FP32 to INT8 and exported the network to TensorFlow Lite, drastically lowering storage and RAM usage and improving inference speed and energy efficiency. This step is a practical requirement for Edge TPU deployment, but it must be validated carefully because poor quantization can degrade performance.\n\nOverall, the optimization workflow followed the course logic: first build a model that performs well in TensorFlow, then compress it (pruning, quantization) and convert it to an optimized TFLite representation. Results from the project materials show a strong size reduction while keeping accuracy in the mid-to-high 90% range, with the quantized TFLite model reaching the sub-megabyte scale, which is what makes embedded deployment realistic.",
      "sistema_de_curso": "The course was organized into 6 theoretical lectures of 1h15 and 3 practical lab sessions of 2h45. Lectures established the fundamentals of edge AI and neural networks, while labs guided the implementation of complete workflows in Python notebooks, including model evaluation and deployment-driven optimization (pruning, quantization, and TensorFlow Lite conversion).",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Be able to explain the main concepts of AI at the edge"},
        {
          "nota": 3,
          "titulo": "Dimension an AI tool for an application at the edge: communication bandwidth, latency, realiability of the model decisions, and privacy."},
        {
          "nota": 3,
          "titulo": "Set up a machine learning workflow on heterogeneous IoT data (tabular, images, temporal series)"},
        {
          "nota": 4,
          "titulo": "Use Python machine learning libraries and compression methods"}
      ],
      "justificativa": "The scores reflect strong understanding of what changes when AI moves from servers to embedded devices, especially the trade-offs around latency, privacy, and resource limits. The labs required building an end-to-end workflow and applying compression methods in practice, which supports the higher rating for Python tooling and model optimization. The slightly lower ratings on dimensioning and heterogeneous workflows match the fact that many engineering decisions were explored through guided exercises rather than fully open-ended system design.",
      "relacao_projeto_profissional": "This discipline is highly relevant for my future as an engineer because AI is increasingly embedded into everyday products and infrastructure. Devices keep getting smarter, and many of them will integrate on-device perception to react locally rather than relying on cloud processing.\n\nAn upcoming internship in a small company makes this connection concrete. The product is a public street-lighting hardware device that uses an embedded camera to detect nearby people and count objects crossing the field of view, with classification across 8 object categories (such as person, bicycle, and car). My role will focus more on C++ microcontroller programming, which was not covered in this course, but the embedded-AI perspective and the deployment mindset will be directly useful. If the existing model must be modified or optimized, the compression and edge constraints studied here should help me understand the trade-offs, communicate with AI-focused teammates, and make practical decisions that keep the system reliable on real hardware."
    },
    
    {
      "id": "energy-for-connected-objects",
      "titulo": "Energy for connected objects",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Raspberry Pi", "SDR", "PMU", "Supercapacitor", "NXP Boards"],
      "tags": ["IoT", "Energy Harvesting", "Wireless Power Transfer", "Battery-free", "Low-power design", "RF"],
      "imagens": ["assets/img/energy.png", "assets/img/energy_lab.jpg", "assets/img/energy_setup.jpg"],
      "relatorio_pdf": "reports/energy_connected_objects.pdf",
      "descricao": "Energy for Connected Objects focused on powering low-power IoT nodes without wires and without conventional batteries, combining energy storage, ambient energy harvesting, and wireless power transfer. The course linked the physics of energy conversion to the concrete design decisions required to build energy-autonomous sensing nodes.\n\nThe hands-on work clarified what “battery-free” means in real engineering terms: quantifying the energy needed to complete a task, estimating what power levels are realistically available, and selecting an architecture that remains functional under fluctuating inputs. A key case study followed a power-budget approach for sensors embedded in concrete for Structural Health Monitoring, where maintenance is impractical and the system must operate reliably over long periods. The final lab report documented the full chain from RF capture to DC power management, including constraints such as rectifier non-linearities and propagation effects.\n\nBeyond this baseline study, an additional energy-autonomy report was carried out on our innovative smart-access project for a vehicle fleet. Combining both perspectives helped bridge theoretical feasibility and field-ready feasibility by validating assumptions through measurements and realistic lifetime calculations.",
      "tecnica": "The course covered the main ways to supply connected objects in constrained environments: electricity storage, ambient energy harvesting (light, mechanical, thermal, electromagnetic), and wireless power transfer using dedicated sources. Design decisions were framed around application constraints such as environment, mobility, range, and duty cycle, with a strong emphasis on the fact that wireless sensing nodes typically operate in short activity bursts separated by long idle periods.\n\nA rectenna-based architecture was used as a reference for electromagnetic harvesting and radiative wireless power transfer, highlighting the full chain from RF capture to usable DC power: antenna, matching and rectification, filtering/storage, and power management. System-level performance was treated as a co-optimization problem, where antenna characteristics, polarization alignment, rectifier non-linearities, and power-management behavior all shape the final DC output.\n\nIn the lab work, a red LED load was used to compare two consumption strategies. Direct consumption relied on a minimal chain (antenna to rectifier to LED), producing immediate response but tying brightness to instantaneous received power and distance. Store-then-use introduced a power management unit, a buck-boost stage, and a supercapacitor so energy could be accumulated and then discharged in a controlled way, improving repeatability at the cost of additional losses and longer charge time. MPPT behavior was also part of the interpretation, since periodic operating-point adjustments create visible oscillations in measured voltage and current.\n\nThe required energy-study report extended the same reasoning to two realistic application contexts. A first case studied energy budgeting for sensors embedded in concrete for Structural Health Monitoring, where battery replacement is impractical and the design must rely on harvested or wirelessly transferred energy plus careful storage and duty cycling.\n\nA second case focused on an innovative keyless-access system for a corporate fleet, developed with ACTIA. The architecture combines a low-power presence layer and short UWB ranging phases, which makes energy management a primary constraint for long parked periods. Measurement methodology was treated as an engineering problem on its own: baseline measurements were attempted with a power analyzer, then a shunt-resistor method on the 5 V supply line was adopted to estimate current profiles under realistic operating conditions.\n\nDatasheet analysis was used to break down the consumption of each UWB-related chip and to highlight a key lesson: current draw cannot be inferred from isolated component values only, because the board architecture and integration choices (peripherals, regulators, debug circuitry, operating modes) materially change the baseline consumption. The study therefore combined datasheet figures with practical measurements and a deployment-oriented model to estimate system autonomy.\n\nThe main conclusion was that, without an additional power strategy, the vehicle-side system would provide only a little more than 5 days of autonomy under conservative battery state-of-charge limits. This is operationally critical for a fleet scenario: a single week of collective holiday could leave the entire fleet non-functional, forcing the access infrastructure to shut down to protect the starter battery. Mitigation directions discussed in the report included designing a minimal dedicated hardware architecture, enforcing an event-driven duty cycle where UWB is enabled only when required, and adding an auxiliary energy source or buffer when long idle periods must be tolerated.",
      "sistema_de_curso": "The course was organized into four 1h15 lecture sessions and two laboratory 2h45 sessions, moving from general concepts (energy, storage, harvesting) to electromagnetic wireless power transfer and design guidelines for low-power connected objects. Assessment relied on lab attendance and a group report summarizing the full work carried out (context, choices, issues and solutions, and conclusions), with an additional reflection on energy autonomy for an innovative project.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Know how to harvest/transfer, store and manage power for connected objects, and how to increase power efficiency"
        },
        {
          "nota": 4,
          "titulo": "Be able to optimize the power consumption of connected objects"
        },
        {
          "nota": 4,
          "titulo": "Be able to design and implement an energy-autonomous and battery-free connected object"
        }
      ],
      "justificativa": "These scores match the combination of theory and applied work delivered in the course. The lab validated end-to-end reasoning from load requirements to rectification, storage, and power-management behavior, while the energy-study report translated the same framework to real constraints where measurement choices, board architecture, and duty cycle dominate conclusions. Writing the report required turning observations into operational design rules, and it clarified how quickly an apparently “small” current becomes a fleet-scale availability risk when vehicles remain parked for several days.",
      "relacao_projeto_profissional": "Energy is a first-class constraint in embedded and IoT engineering, and this course strengthened the ability to reason from requirements to architecture choices with quantified trade-offs. The rectenna and wireless power chain concepts are directly relevant for battery-free sensing, maintenance-free deployments, and RF-constrained environments like infrastructure monitoring.\n\nThe energy-study report is particularly aligned with industry practice: it focused on measuring and modeling a real product to obtain conclusive decisions, rather than stopping at nominal datasheet values. That mindset translates well to automotive and industrial projects, where autonomy targets, parked-time scenarios, and system availability must be validated with realistic measurements and conservative assumptions. The fleet-access case also reinforced that energy constraints are not only a device problem but an operational problem, since a week-long idle period can break a service if autonomy is underestimated."
    },

    {
      "id": "m2m",
      "titulo": "Machine to Machine",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["ESP8266 (NodeMCU)", "C++", "MQTT", "Eclipse Mosquitto", "Arduino IDE", "Node-RED", "Home Assistant"],
      "tags": ["IoT", "MQTT protocol", "MQTT Broker", "Communications", "Smart Home", "ArduinoHA"],
      "imagens": ["assets/img/m2m.jpeg", "assets/img/m2m_esp8266.png", "assets/img/m2m_node-red.png"],
      "relatorio_pdf": "reports/m2m.pdf",
      "descricao": "This course strengthened how to think about machine-to-machine communication as an engineering system: devices, middleware, and the application layer working together in a coherent architecture. The main focus was understanding how constrained IoT nodes can exchange data reliably and securely using MQTT, then building an end-to-end pipeline that remains easy to test, extend, and supervise.\n\nBeyond the technical stack, the course was especially useful because it connected directly to projects running in parallel during the semester. Concepts and tools from the labs were reused in an open-source project (a gas sensor application) and also in my Innovative Project (keyless car entry) where MQTT is part of the cloud integration through AWS IoT Core, which helped reinforce the “why” behind each design choice.",
      "tecnica": "The course covered IoT fundamentals and platform challenges (heterogeneity, interoperability, security, and quality of service), then narrowed down to practical middleware building blocks for connected systems. MQTT was introduced as a lightweight publish/subscribe protocol designed for sensors and actuators, relying on a broker to manage client sessions and route messages through topic-based queues. Key topics included MQTT over TCP/IP, topic hierarchies, retained messages, keep-alive mechanisms, will messages for disconnect handling, and QoS levels (0, 1, 2) to balance reliability versus overhead.\n\nHands-on work started by installing and validating an Eclipse Mosquitto broker and testing publish/subscribe behavior using command-line clients. The labs then moved to embedded implementation with an ESP8266 (NodeMCU) programmed in Arduino IDE: Wi-Fi connectivity, MQTT client setup, and bidirectional messaging with both publications (telemetry/events) and subscriptions (remote commands). A simple smart-home scenario structured the application logic around dedicated topics for button state, luminosity measurements, and light commands, illustrating how manual and automatic behaviors can coexist through clear topic design.\n\nNode-RED was used for fast prototyping of higher-level applications on top of MQTT. Flow-based logic enabled quick parsing, routing, and rule evaluation, and dashboards provided real-time visualization and interaction (charts, controls, debug traces). The same middleware reasoning was later extended to specialized platforms with Home Assistant, where entities, services, and device organization provide a more structured supervision layer. Using ArduinoHA, the ESP8266 was integrated as a Home Assistant device and exposed controllable entities, highlighting naming conventions, scalability considerations, and practical security measures such as authentication and the possibility of TLS when needed. Energy-related considerations were also addressed through message frequency, connection efficiency, and the availability of low-power modes on the ESP8266 for battery-powered deployments.",
      "sistema_de_curso": "The course combined 3 lecture sessions (1h15 each) with 4 laboratory sessions (2h45 each). The course content introduced IoT architecture and interoperability challenges, then focused on MQTT principles and rapid prototyping with Node-RED, before exploring specialized middleware with Home Assistant. The labs progressively validated an end-to-end chain: broker installation and testing, embedded MQTT client development on ESP8266, application orchestration and dashboards in Node-RED, and device integration into Home Assistant using ArduinoHA.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Know how to situate the main standards for the Internet of Things"
        },
        {
          "nota": 4,
          "titulo": "Deploy an architecture compliant to an IoT standard and implement a sensor network"
        },
        {
          "nota": 4,
          "titulo": "Deploy and configure an IoT architecture"
        },
        {
          "nota": 4,
          "titulo": "Interact with the different resources of the architecture using REST services"
        },
        {
          "nota": 4,
          "titulo": "Integrate a new technology into the deployed architecture"
        }
      ],
      "justificativa": "The rating is high across all competencies because the course required both understanding and execution: selecting the right communication model, deploying the broker infrastructure, building an embedded client, and validating interactions end-to-end with real tools. The lab sequence also demonstrated how to move from a working prototype (MQTT + Node-RED) to a more structured ecosystem (Home Assistant with entities and services), which reflects real product workflows. I saw immediate impact in other semester projects, since Node-RED and MQTT were reused in an open-source gas sensor application and in my Innovative Project (keyless car entry) with AWS IoT Core, reinforcing the transferability of these skills.",
      "relacao_projeto_profissional": "This course maps directly to embedded and IoT roles where the core challenge is connecting devices to a reliable middleware layer and exposing data/controls to applications safely and maintainably. MQTT-based architectures are common in smart home, industrial monitoring, and connected mobility, and the ability to design topics, reason about QoS, and debug broker-level behavior is practical day one value.\n\nOn a personal level, the course also improved confidence in technical discussions during recruiting. Knowledge from this module helped me during an interview for “Innovation IoT: Connectez un Objet Intelligent via de multiples Protocoles de Communication” at Thales, where MQTT and LwM2M were part of the expected communication stack, and the lab-driven understanding made it easier to explain architectural choices and trade-offs."
    },

    {
      "id": "software-engineering",
      "titulo": "Software engineering",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Java", "Microservices", "Agile method"],
      "tags": [],
      "imagens": ["assets/img/software-engineering.png", "assets/img/architecture-diagram.jpg"],
      "relatorio_pdf": "",
      "descricao": "This short module was used as a structured kickoff for an Architecture Service project, focusing on how to translate a real scenario into a coherent service architecture before implementation. The work centered on clarifying responsibilities, defining service boundaries, and validating architectural choices early to avoid rework later.\n\nThe selected use case was a smart airport safety workflow, where sensing, decision-making, actuation, and traceability were separated into clear components to support maintainability and future evolution.",
      "tecnica": "The course emphasized architectural thinking before coding, especially for microservice-based systems where responsibilities must be explicit and interfaces must remain stable. The main deliverable was a system diagram capturing the end-to-end flow and the role of each service in the architecture.\n\nThe proposed design modeled three independent sensing functions deployed at an airport fuel station, each represented as its own microservice. These sensing services report to a controller microservice responsible for aggregating events and coordinating the safety logic. A dedicated historical microservice stores operational data to support traceability, later analysis, and audit requirements.\n\nActuation was separated into an actuator microservice that triggers emergency responses at the airport fire station. In the defined workflow, this actuator microservice is responsible for activating a siren, turning on an emergency light, and opening all gates so that fire trucks can leave immediately. This separation keeps safety actions isolated, testable, and replaceable without modifying the sensing layer.\n\nAgile principles were discussed as a practical way to de-risk architecture work: iterating from a high-level diagram to refined service contracts, prioritizing the most critical flows first, and validating assumptions early with stakeholders.",
      "sistema_de_curso": "The course was organized as two 1h15 sessions, used to brainstorm the service architecture, draft the microservice workflow, and validate the proposed structure with the instructor before moving toward implementation in the broader project.",
      "matriz_competencia": [
        {
          "nota": 2,
          "titulo": "Apply DevOps : Continuous integration and continous deployement (CI/CD) on a microservice based architecture"
        },
        {
          "nota": 3,
          "titulo": "Conduct a project following the agile method"
        }
      ],
      "justificativa": "A score of 2 for DevOps/CI/CD reflects the fact that these topics remained conceptual in this module, without hands-on implementation of pipelines or deployment automation. The agile method earned a 3 because it was effectively used to structure the early project phase and converge on an architecture efficiently, while deeper execution practices and longer iteration cycles were left to subsequent project work.",
      "relacao_projeto_profissional": "This module reinforced a habit that directly carries into professional engineering: defining system boundaries, data flow, and responsibilities before writing code, especially when multiple services must evolve independently. The airport safety scenario also mirrors real constraints found in industrial systems, where traceability, reliability, and clear separation between sensing, decision, and actuation are essential.\n\nIn future embedded and IoT-facing roles, this approach supports designing robust service backends around physical devices, reducing integration risk, and enabling maintainable growth from prototype to production."
    },

    {
      "id": "service-architecture",
      "titulo": "Service architecture",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Java", "Spring Boot", "Maven", "MySQL Workbench", "Eclipse IDE", "Git/GitHub"],
      "tags": ["Service-Oriented Architecture", "Microservices", "RESTful Services", "Distributed Architecture", "Backend Engineering", "System Integration"],
      "imagens": ["assets/img/service-architecture.png", "assets/img/architecture-final-test.png"],
      "relatorio_pdf": "reports/service_architecture.pdf",
      "descricao": "This course built a structured understanding of Service-Oriented Architecture (SOA) and how service-based systems are designed, exposed, and integrated in distributed environments. The focus was on the architectural principles behind interoperable services, including clear contracts, loose coupling, separation of concerns, and the practical tradeoffs between different service styles (SOAP and REST) when building real systems. \n\nTo make these concepts concrete, the course used a realistic integration case study where multiple services must collaborate to monitor a situation, compute decisions, trigger actions, and keep traceable records. The project work served as an applied sandbox to practice service decomposition, API design, orchestration patterns, and end-to-end verification across independently running components.",
      "tecnica": "The course introduced Service-Oriented Architecture (SOA) fundamentals and how interoperability is achieved through well-defined service contracts, standardized communication, and loose coupling. In practice, this means separating responsibilities into services that expose clear interfaces, so implementations can evolve independently without breaking the overall system. The course compared SOAP and REST as two major approaches to web services: SOAP emphasizes formal contracts and standardized message structures, while REST focuses on resource-oriented APIs over HTTP and is often more lightweight for service-to-service communication in modern systems.\n\nThese principles were practiced through a microservices architecture implemented as multiple independent Spring Boot applications. Each microservice was created with Spring Initializr and built with Maven, ensuring consistent dependency management and reproducible packaging across services. To enable local integration in a distributed style, each service was configured to run on its own port, allowing them to start independently while still communicating through HTTP calls.\n\nA strict separation of concerns was enforced by design: sensor services only hold and expose their own state; the decision engine contains the decision logic but does not own sensor state; the actuator service executes commands without business rules; and persistence is isolated in a dedicated history service. This architecture keeps coupling low, makes responsibilities explicit, and mirrors real deployments where devices, control logic, and storage are decoupled but integrated through stable APIs.\n\nCommunication between services was implemented through REST interfaces. Sensor microservices expose endpoints to update and retrieve their simulated readings, which allowed external testing and controlled scenario execution. The decision engine retrieves the live state of each sensor by performing REST requests to the corresponding services, then evaluates predefined rules to determine whether an emergency exists. When a critical condition is detected, the decision engine calls the actuator service endpoints to activate the siren, switch on emergency lights, and open the gate. This workflow demonstrates a practical orchestration pattern where one service coordinates a system-wide response without directly owning the components it controls. \n\nTraceability was treated as a first-class requirement through a dedicated History Service backed by a MySQL database managed via MySQL Workbench. Instead of letting every microservice access the database, persistence is centralized behind the history service API, which becomes the single entry point for storing events. Data was mapped via JPA so that records are created automatically as part of the normal execution flow. The database schema was designed around an events table that stores timestamps, sensor type, measured value, and a description of the triggered action, enabling post-analysis and audit trails of both observations and reactions. \n\nValidation was performed through scenario-based integration tests using Postman. Scenarios covered normal operation, gas leak detection, fire detection, manual alarm activation, and combined sequences to demonstrate global coherence. During these tests, sensor updates were posted manually, the decision engine was invoked to evaluate the system, actuators were triggered accordingly, and the resulting event traces were verified in the MySQL database to confirm that the end-to-end architecture behaves as expected.",
      "sistema_de_curso": "The course combined 6 remote lectures covering SOA, RESTful services, and microservices, plus 10 exercise sessions (1h15) and 4 longer sessions (2h45) dedicated to implementing and integrating the final solution with the professor’s support.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Understand the related concepts and features of a Service Oriented Architecture"
        },
        {
          "nota": 4,
          "titulo": "Develop a distributed architecture using  web services"
        },
        {
          "nota": 4,
          "titulo": "Deploy and configure an SOA using SOAP"
        },
        {
          "nota": 4,
          "titulo": "Implement and test a microservices architecture using Spring BootDeploy and configure an SOA using REST"
        },
        {
          "nota": 4,
          "titulo": "Design, develop, and deploy a microservice architecture"
        }
      ],
      "justificativa": "These scores reflect strong alignment with the course objectives: SOA concepts were applied to structure a system into well-bounded services with clear interfaces, and the final implementation demonstrated distributed behavior through REST-based integration and a clean separation of responsibilities. The work also validated traceability through a dedicated persistence service and database verification, which matches SOA concerns in real deployments where audit trails and system observability are required.",
      "relacao_projeto_profissional": "This course strengthened backend architecture skills that transfer directly to IoT and embedded-connected systems, especially when devices and edge services must report state, trigger actions, and maintain audit trails. Concepts like service contracts, loose coupling, and traceability map well to fleet management, safety monitoring, and industrial supervision platforms where reliability and post-incident analysis matter. \n\nEven if Java and Spring are not the primary tools planned for future projects, the architectural reasoning remains valuable: decomposing a system into independently deployable services, designing robust API boundaries, and validating distributed workflows with realistic scenarios are skills that carry across stacks (cloud-native platforms, IoT backends, and event-driven systems)."
    },

    {
      "id": "security-connected-objects",
      "titulo": "Security for connected objects",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias":  ["IoT Security", "Web Security", "Quantum Key Distribution", "Cryptography"],
      "tags": ["Threat Modeling"],
      "imagens": ["assets/img/security-connected-objects.png", "assets/img/criptography.png", "assets/img/quantum_communication.jpeg"],
      "relatorio_pdf": "reports/security.pdf",
      "descricao": "This course built a practical view of security in connected systems, covering how vulnerabilities emerge from architecture choices, implementation details, and operational constraints typical of IoT devices. The content linked real attack paths to realistic countermeasures, with an emphasis on understanding what an attacker can do and what defenses actually reduce risk.\n\nHands-on work complemented the theory by turning “security concepts” into observable behaviors: exploitation steps, impact evaluation, and the tradeoffs between mitigation strength, complexity, and feasibility in resource-constrained systems.",
      "tecnica": "The course addressed device and system security starting from the IoT attack surface: physical access, debug interfaces, firmware exposure, insecure defaults, and weak isolation between components. Threat modeling helped map assets, trust boundaries, and attacker capabilities, then translate them into concrete risks and mitigations. The work also highlighted how embedded constraints influence security design, including limited compute, limited memory, and long-lived deployments that must remain maintainable and resilient over time.\n\nWe also focused on web interfaces and dashboards often used to configure or monitor connected devices. Typical vulnerabilities were explored through practical analysis of a PHP and MySQL application, including injection-driven authentication bypass, unsafe dynamic includes leading to local file inclusion, and escalation paths enabled by insecure server configurations. Client-side and session-related weaknesses were also discussed to show how attacks such as XSS and CSRF can impact configuration integrity, user sessions, and device control workflows.\n\nQuantum communications introduced the motivation for quantum-safe thinking and the basic principles behind quantum key distribution, with BB84-style mechanisms used to explain how interception attempts affect the system. The course also emphasized a critical systems perspective: quantum techniques do not remove the need for authentication, and a secure deployment still depends on correctly handling identity, trust, and man-in-the-middle risks at the classical layer.\n\nCryptography provided the foundation for secure communications and data protection, progressing from basic concepts to modern primitives. The differences between symmetric and asymmetric approaches were used to reason about confidentiality, integrity, and authenticity, including encryption, signatures, and key management. Practical emphasis was placed on why correct key handling, certificate validation, and secure protocol usage matter more than simply “using crypto”, since many real compromises result from integration mistakes rather than broken algorithms.",
      "sistema_de_curso": "The course combined 10 lecture sessions (1h15 each) delivered by three different instructors with 8 lab sessions focused on observing and reproducing attacks in practice, supported by written deliverables linked to the hands-on work.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Understand the fundamentals of security"
        },
        {
          "nota": 3,
          "titulo": "Be able to identify security weaknesses in an IoT architecture"
        },
        {
          "nota": 3,
          "titulo": "Be able to assess the impact of exploiting a security vulnerability in an IoT architecture"
        },
        {
          "nota": 3,
          "titulo": "Be able to propose adequate security counter-measures"
        },
        {
          "nota": 3,
          "titulo": "Be able to design secure communication protocols for IoT"
        },
        {
          "nota": 3,
          "titulo": "Understand the secure quantic communications"
        }
      ],
      "justificativa": "The fundamentals were strongly reinforced because the course repeatedly connected concepts to concrete exploitation scenarios and clear impact discussions. Practical work made it easier to recognize weaknesses and propose countermeasures, even when the full depth of protocol design was beyond the scope of a single module. The quantum communication part was introduced in a meaningful way, but the learning outcome felt less stable due to the difficulty of following the lab execution and the limited time to iterate.",
      "relacao_projeto_profissional": "This course connects directly with work on connected devices, where security becomes a first-class requirement rather than an optional add-on. Protecting critical messages and device control paths requires secure communication foundations (authentication, certificates, encryption) and careful attention to implementation details that often become the weakest link.\n\nIt also matches the direction of many industrial systems migrating from wired to wireless communication. Even when power and reliability constraints initially push designs toward cables, the move to radio links increases exposure and makes security engineering part of the baseline skillset for embedded and IoT roles."
    },

    {
      "id": "wireless-sensor-networks",
      "titulo": "Wireless Sensor Networks",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": [],
      "tags": [],
      "imagens": ["assets/img/wsn.jpg"],
      "relatorio_pdf": "reports/wireless_sensor_networks.pdf",
      "descricao": "",
      "tecnica": "",
      "sistema_de_curso": "",
      "matriz_competencia": [
        {
          "nota": 0,
          "titulo": ""
        }
      ],
      "justificativa": "",
      "relacao_projeto_profissional": ""
    },

    {
      "id": "cloud-and-edge-computing",
      "titulo": "Cloud and Edge Computing",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Docker", "OpenStack", "Kubernetes", "VirtualBox", "Node.js"],
      "tags": ["Cloud Infrastructure", "Virtualization", "Containers", "OpenStack", "Kubernetes", "Cloud Networking"],
      "imagens": ["assets/img/edge-computing.jpg"],
      "relatorio_pdf": "reports/edge_computing.pdf",
      "descricao": "Cloud and Edge Computing provided a practical path from virtualization fundamentals to deploying and operating service-based systems on modern cloud infrastructure. The work connected concepts such as VMs versus containers, infrastructure abstraction, and network isolation with hands-on deployments that exposed the operational reality behind “elastic” and “on-demand” resources.\n\nAcross a sequence of labs, the course progressively moved from local virtualized environments to an IaaS platform, and finally to container orchestration on top of that infrastructure. Instead of staying at a conceptual level, each step required making services reachable, keeping deployments reproducible, and validating behavior with real client requests and network constraints.",
      "tecnica": "The course started by grounding cloud and edge discussions in virtualization primitives and isolation models. Virtual machines were treated as full OS-level environments managed by a hypervisor, while containers were approached as process-level isolation sharing the host kernel. This difference directly influenced startup time, resource overhead, portability, and the operational trade-offs when packaging and deploying services.\n\nA first layer of practical work used VirtualBox to understand how “a service on a machine” becomes “a service on a network.” The setup relied on NAT networking with explicit port forwarding to expose services running inside the guest VM to the host environment. That exercise made connectivity constraints tangible: without correct forwarding rules and consistent addressing, the service exists but remains unreachable. The same logic later reappeared at cloud scale through router configuration, security groups, and public IP exposure. \n\nContainerization was then used to turn application deployment into a repeatable artifact. Docker images were built from Dockerfiles, making dependencies and runtime configuration explicit and reproducible. Rather than deploying “by hand,” the application lifecycle became: define the build context, produce an image, run containers with clear ports and environment variables, and validate behavior with client calls. This step also clarified why containers are a natural fit for service-based systems: consistent packaging, fast instantiation, and an interface-driven runtime model.\n\nThe infrastructure focus moved to OpenStack as an IaaS provider, covering the practical architecture behind compute, image management, identity, and networking. Work on Horizon and CLI workflows exposed a complete provisioning chain: selecting an image and flavor, creating instances, attaching them to a private network, and controlling traffic using security groups. A key aspect was network reachability from outside the cloud: public exposure required routing through a virtual router and binding a Floating IP, which mirrors how real providers separate tenant networks from the public internet.\n\nService-based deployment was concretely exercised through a microservice-style Node.js application distributed across multiple virtual machines. Each service instance had to run reliably, be reachable on the expected ports, and communicate across subnets. This introduced realistic cloud networking problems, including multi-network topologies and the need for routing decisions rather than assuming a single flat network. Static routes were configured to enable inter-subnet communication, showing how segmentation improves control but increases configuration complexity. \n\nAutomation and orchestration were addressed by shifting from manual provisioning toward tool-assisted lifecycle management. The course emphasized that cloud value comes from repeatability: deployments should be created, destroyed, and recreated with consistent results. This perspective set the stage for orchestrators that manage placement, networking, and service availability across a pool of resources, rather than relying on per-machine administration.\n\nFinally, Kubernetes was deployed on top of OpenStack to reach a production-like orchestration layer. A cluster was bootstrapped using kubeadm, followed by configuring a CNI plugin (Calico) to enable pod networking. The exercise highlighted how orchestration changes the unit of deployment from “a VM running a process” to “a service described declaratively,” with scheduling, scaling primitives, and stable service access patterns. Using ClusterIP services reinforced internal service discovery and load distribution inside the cluster, complementing earlier lessons on exposing endpoints to the outside world.",
      "sistema_de_curso": "The course was organized into 4 lectures of 1h15 and 6 hands-on practical sessions of 2h45. The practical work followed step-by-step lab instructions, moving from local virtualization exercises to OpenStack provisioning and finally Kubernetes cluster deployment and service exposure.",
      "matriz_competencia": [
        {
          "nota": 3,
          "titulo": "Understand the concept of virtualization and the fundamental differences between virtual hosts (VM versus containers)"
        },
        {
          "nota": 3,
          "titulo": "Understand the concept of cloud computing"
        },
        {
          "nota": 3,
          "titulo": "Understand the architecture of IaaS provider"
        },
        {
          "nota": 3,
          "titulo": "Deploy a service-based applications in the cloud"
        },
        {
          "nota": 3,
          "titulo": "Automate the service-based applications provisioning with service orchestrators"
        },
        {
          "nota": 3,
          "titulo": "Deploy service-based applications in cloud-edge continuum and setup QoS management"
        }
      ],
      "justificativa": "A score of 3 makes sense because the course covered the full chain from virtualization to cloud infrastructure and orchestration, and the labs did result in working deployments. At the same time, the practical sessions were often closer to following a “recipe” provided by the professor, where commands were copied into the terminal with limited time to deeply understand each component. Several topics were also skipped because the class was progressing slowly and prioritizing basic execution over a deeper explanation, which meant parts of the workflow were completed without fully understanding what was happening internally.",
      "relacao_projeto_profissional": "This course gave a concrete first exposure to cloud infrastructure and orchestration tooling that appears in many modern software stacks. However, this is not an area that feels central to the type of embedded and connected-systems work I currently target, where hardware constraints, firmware, sensing, and edge-side integration usually dominate the engineering effort.\n\nStill, if a future role requires operating services on an IaaS platform or interacting with container orchestration, the course provides a starting point and vocabulary to re-enter the topic. With dedicated revision and more deliberate practice beyond the step-by-step labs, it should be possible to apply these concepts in a more autonomous and confident way when needed."
    },
    
    {
      "id": "lp-wpan-protocols",
      "titulo": "Communication protocols for LP-WPAN",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": [],
      "tags": [],
      "imagens": ["assets/img/communication-protocols.jpg"],
      "relatorio_pdf": "",
      "descricao": "",
      "tecnica": "",
      "sistema_de_curso": "",
      "matriz_competencia": [
        {
          "nota": 0,
          "titulo": ""
        }
      ],
      "justificativa": "",
      "relacao_projeto_profissional": ""
    },

    {
      "id": "emerging-network",
      "titulo": "Emerging network (SDN, NGN)",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": [],
      "tags": [],
      "imagens": ["assets/img/emerging-network.jpeg"],
      "relatorio_pdf": "",
      "descricao": "",
      "tecnica": "",
      "sistema_de_curso": "",
      "matriz_competencia": [
        {
          "nota": 0,
          "titulo": ""
        }
      ],
      "justificativa": "",
      "relacao_projeto_profissional": ""
    },

    {
      "id": "from3gto6g",
      "titulo": "From 3G to 6G",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["3GPP","LTE","5G", "6G","Literature Review","Presentation"],
      "tags": ["Wireless Communications","Mobile Networks","Telecom Standardization","IoT","Spectrum","EM Waves","mmWave","Health & Safety","Semiconductor Scaling (nm/Å nodes)"],
      "imagens": ["assets/img/from3gto6g.jpg"],
      "relatorio_pdf": "reports/from3gto6g.pdf",
      "descricao": "In this course, a structured understanding was built around how mobile networks evolved from 3G to today's 5G era and how the industry is already shaping the path toward 6G. The focus went beyond “what changed” generation by generation (services, performance, spectrum), and also addressed why it changed through market dynamics, technology scaling, and global standardization processes.\n\nA controversial but essential topic for modern wireless systems was also explored: the potential health impacts of electromagnetic (EM) waves and the societal concerns surrounding mobile deployments. The work aimed to keep a balanced view, separating established physical mechanisms (mainly thermal effects) from debated non-thermal hypotheses, while explaining why scientific opinions can diverge depending on methods, exposure metrics, and evidence quality.",
      "tecnica": "The course covered the ecosystem that drives mobile-network innovation, linking technical evolution to market cycles, investment dynamics, and the push from smartphones, IoT adoption, and industrial connectivity. This “market lens” clarified why each new generation is not only a performance upgrade, but also a response to demand, competition, and feasibility at scale.\n\nKey topics included how mobile technologies become “official” through global standardization. The role of 3GPP was studied as a partnership framework that consolidates specifications defining architecture, protocol layers, interfaces, requirements, and testing for GSM/UMTS/LTE/5G NR, while also structuring the transition to 5G-Advanced and early 6G roadmaps via Release planning and timelines.\n\nFrom a physical-layer perspective, the work focused on how spectrum selection and propagation constraints shape system design. Coverage vs. capacity trade-offs were connected to the progressive move toward higher frequencies, and the implications were discussed in terms of wavelength, antenna integration, and the practical need for antenna arrays, beamforming, and massive MIMO to maintain link budget and increase throughput. Basic RF relationships (frequency-wavelength links and related measurement concepts) were used to ground these conclusions.\n\nThe hardware dimension was also emphasized: semiconductor scaling as an enabler for higher integration, stronger compute capabilities, and tighter coupling between communication and AI features. Expected directions for 6G were examined, including wider bandwidths (potentially extending toward sub-THz/terahertz ranges), improved localization, network automation with AI/ML, and the emergence of concepts such as battery-less or “zero-energy” devices for massive sensing and data collection.\n\nFor the selected topic (Cancer & EM waves), the course required a state-of-the-art review approach. Exposure concepts (device proximity, infrastructure, and typical field levels) were placed alongside the mainstream emphasis on thermal effects, then contrasted with publications that argue for possible long-term non-thermal impacts versus sources highlighting limitations in replication, dosimetry, and the difficulty of extrapolating lab conditions to real-world human physiology. I presented this synthesis in an evaluated oral talk, concluding with a pragmatic precaution stance: reduce unnecessary exposure when feasible without turning uncertainty into alarmism.",
      "sistema_de_curso": "The course was organized as 6 sessions of about 1h15: 2 instructor-led lectures to build the historical and technical foundation (market context, spectrum, standardization, technology scaling, roadmap to 6G), followed by 4 student presentation sessions. Students worked in pairs, each selecting a topic (e.g., 6G modulation, satellites, vehicle connectivity, mmWave threats, mobile addiction, cancer & EM waves) and delivering a 10-15 minute oral presentation followed by Q&A, which served as the main evaluation method.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Mastery of new mobile network technologies"}
      ],
      "justificativa": "These ratings reflect what was practiced in the course: a clear generation-by-generation model (services, spectrum, and KPIs) was consolidated, connected to the 3GPP release logic, and grounded with RF fundamentals explaining why higher frequencies require new antenna strategies. The health-focused topic was handled as a structured synthesis rather than a “settled” claim, highlighting mechanisms, evidence limits, and interpretation gaps then delivered through an evaluated oral presentation with a responsible conclusion.",
      "relacao_projeto_profissional": "This course directly supports my professional trajectory in embedded systems and connected devices because it connects real industry constraints (standardization, roadmap timing, spectrum availability, hardware scaling) to the design decisions behind IoT and mobile connectivity. Understanding the 3GPP ecosystem and the evolution from LTE to 5G NR and beyond helps position cellular IoT technologies within realistic constraints for products and industrial systems. This knowledge also proved immediately useful in my interview at Thales for the “R&I: Communications V2X et Sécurité 5G” role, where I could discuss these constraints and trade-offs with concrete technical grounding.\n\nIt also strengthened my ability to account for societal and safety concerns that still influence engineering decisions. For roles involving IoT, smart systems, or telecom-connected embedded products, discussing EM exposure questions responsibly without exaggeration, but with technical grounding and awareness of uncertainty adds value when designing systems, documenting risk, or communicating with stakeholders."
    },

    {
      "id": "english",
      "titulo": "English",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": [],
      "tags": [],
      "imagens": ["assets/img/learn-english.jpeg"],
      "relatorio_pdf": "",
      "descricao": "",
      "tecnica": "",
      "sistema_de_curso": "",
      "matriz_competencia": [
        {
          "nota": 0,
          "titulo": ""
        }
      ],
      "justificativa": "",
      "relacao_projeto_profissional": ""
    },

    {
      "id": "individualized-professional-development",
      "titulo": "Individualized Professional Development",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": [],
      "tags": [],
      "imagens": ["assets/img/ipd.png"],
      "relatorio_pdf": "",
      "descricao": "",
      "tecnica": "",
      "sistema_de_curso": "",
      "matriz_competencia": [
        {
          "nota": 0,
          "titulo": ""
        }
      ],
      "justificativa": "",
      "relacao_projeto_profissional": ""
    },

    {
      "id": "team-management",
      "titulo": "Team Management",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": [],
      "tags": [],
      "imagens": ["assets/img/management.png"],
      "relatorio_pdf": "",
      "descricao": "",
      "tecnica": "",
      "sistema_de_curso": "",
      "matriz_competencia": [
        {
          "nota": 0,
          "titulo": ""
        }
      ],
      "justificativa": "",
      "relacao_projeto_profissional": ""
    },

    {
      "id": "ethics",
      "titulo": "Social Psychology and Ethics",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Presentation","Research"],
      "tags": ["Ethics","Social Psychology","Group Dynamics", "Intercultural Communication"],
      "imagens": ["assets/img/ethics.jpg"],
      "relatorio_pdf": "reports/ethics.pptx",
      "descricao": "\nIn this course I was introduced to social psychology as a human sciences discipline that studies the relationships between individuals, groups and situations. We explored how group dynamics, influence, stereotypes, intercultural relations, manipulation, conflict management and psychosocial risks shape behaviours in everyday life and in professional settings.\n\nAll these concepts were constantly questioned from an ethical perspective: who is responsible for what, what makes an action just, and what it means for an action to be truly free. A central part of the course was also devoted to ethics in engineering and to intercultural communication, which I worked on through a dedicated presentation on intercultural relations and cultural adaptation.",
      "tecnica": "\nThe course began with a detailed analysis of the movie 12 Angry Men (1957), used as a practical case for social influence and group decision-making. Through this film, group pressure, minority influence, stereotypes linked to social class and origin, and the tension between emotional and rational arguments were examined. The character who insists on questioning the evidence served as an example of how one individual can progressively shift a group decision by demanding a more rigorous, fact-based discussion.\n\nKey topics included the foundations of social psychology and group dynamics, at the crossroads between psychology and sociology. Lectures covered the interaction between individual, group and situation, with reference to authors such as Elton Mayo (Hawthorne effect and the role of social motivation), Jacob Moreno (sociometry and affective networks inside groups) and Kurt Lewin (field theory and group dynamics as a system of forces). Criteria for defining a group were presented (minimum number of people, shared goals, interdependence, roles, norms and shared values), along with distinctions between crowds, small primary groups, large temporary groups and formal organisations.\n\nAs part of the course, together with a classmate, I prepared and delivered a full presentation on intercultural communication. The work started from the UNESCO definition of culture as a set of values, norms, practices, beliefs and ways of life shared by a group, emphasising that culture also involves invisible dimensions such as communication styles and relationships to time, authority and emotions. The notion of micro-cultures was introduced to describe families, student cohorts, project teams or local communities, each with its own codes and rituals, which explains why people from the same country can behave very differently. Intercultural communication was defined as interaction between people with different cultural references, requiring competences such as active listening, curiosity, reflexivity, the ability to question stereotypes and to manage uncertainty in exchanges.\n\nThe presentation also explored practical strategies for adapting to other cultures: maintaining an open attitude, observing without immediate judgement, adjusting verbal and non-verbal communication (simplifying language, paying attention to body language, respecting hierarchy where it matters) and asking for clarification when necessary. The classic phases of cultural adaptation (honeymoon, slump, realisation and adaptation) were described to show that cultural shock is a normal stage in the learning process. Another key concept was ethnocentrism - the tendency to see one's own culture as the central or superior reference - and the importance of recognising it in order to build more respectful and effective intercultural relations. Practical tools for communicating across cultures were proposed: using clear and concrete language, avoiding jargon and idioms, combining oral explanations with written notes or diagrams, providing concrete examples and regularly checking understanding by asking others to reformulate the message.\n\nOn the ethical side, the course worked with precise distinctions between morality, ethics and deontology. Morality was presented as a set of values and concrete rules that distinguish good from bad, ethics as a reflective process that questions human actions and their consequences, and deontology as the set of duties linked to a professional practice. Several ethical frameworks for decision-making were studied: ethics of reciprocity (“treat others as you would like to be treated”), duty-based ethics (Kantian universal principles), utilitarian ethics (seeking the greatest good for the greatest number) and ethics of conviction (coherence between personal values and actions). These frameworks provided a structured way to analyse dilemmas.\n\nThe course also highlighted a three-question approach to ethical reflection: Where does a practice come from (historical and social origins)? What is it for (meaning and usefulness)? Where is it going (long-term impacts and finalities)? This method was applied to engineering topics to connect technical possibilities with social effects and personal responsibility. Digital ethics completed the technical content with questions about cybercrime, manipulation, privacy and data protection, big data, social media, right to disconnect and the environmental footprint of digital technologies, including energy consumption and electronic waste.\n\nFinally, the responsibilities of engineers were discussed through ethical charters and case studies. Emphasis was placed on the need to balance what is technically possible with what is socially desirable, by assessing risks, long-term impacts and the social acceptability of technologies. This integrated view of ethics, group dynamics and intercultural communication forms a methodological base for future work with connected objects, data and smart systems.",
      "sistema_de_curso": "The course was organised in around 14 sessions of 1h15. Teaching combined a common screening and discussion of 12 Angry Men, interactive lectures based on the professor's slides on social psychology, group dynamics, ethics and digital issues, and student-led presentations. The class was divided into pairs, each pair preparing a 20-30 minute presentation on a specific topic such as influence, manipulation, stereotypes, intercultural relations, conflict management, psychosocial risks or digital ethics, followed by a structured debate with the rest of the group. Readings, short exercises and whole-class discussions were used to connect theory with concrete situations and with the role of engineers.",
      "matriz_competencia": [
        {
          "nota": 3,
          "titulo": "Analyse Group Situations Using Concepts from Social Psychology"},
        {
          "nota": 3,
          "titulo": "Understand Interpersonal Relations in Professional and Intercultural Situations"},
        {
          "nota": 3,
          "titulo": "Integrate Reflection on Socio-Ecological Issues into Career Path"},
        {
          "nota": 3,
          "titulo": "Identify the Ethical Dimensions of Situations and Argue One's Position"},
        {
          "nota": 3,
          "titulo": "Sharpen Critical Thinking, Decentring and Self-Reflection: Meta-Cognition"}
      ],
      "justificativa": "Level 3 is appropriate for all these competencies because they were mobilised repeatedly throughout the course, even if still at a student level rather than in a professional position. Through the film analysis, group presentations and debates, it became possible to identify ethical and intercultural issues while remaining attentive to people's limits and vulnerabilities. Preparing and delivering the presentation on intercultural communication required questioning the objectives and implicit assumptions behind ways of working together, reflecting on stereotypes and ethnocentrism, and considering the social acceptability of behaviours and communication styles. The need to structure arguments, adapt explanations to a diverse audience and react in real time to questions corresponds to agile implementation of chosen strategies. Continuous reflection on personal values, cultural background, biases and reactions - for example in discussions on discrimination, digital surveillance or cultural shock - supported a genuinely reflective evaluation of progress and limitations.",
      "relacao_projeto_profissional": "This course is connected to my professional project as an engineer working with embedded systems, IoT and smart, data-driven technologies in international and multicultural environments. In these fields, technical choices affect privacy, safety, environmental impact, work organisation and power relations inside companies and in society, and they are often implemented by teams composed of people with very different cultural backgrounds. Studying social psychology, ethics and intercultural communication helped to see teams, organisations and users as complex groups with histories, norms and expectations, and to anticipate how technologies and communication styles can reinforce or challenge existing dynamics.\n\nFor future roles in industry or research, this background supports the ability to question the purpose of the systems being designed, to evaluate their social and environmental impacts, and to defend responsible choices when facing dilemmas between performance, cost and ethical concerns. The specific work on intercultural communication strengthened the capacity to collaborate with international colleagues, adapt language and behaviour, and transform cultural differences into an asset rather than a source of conflict. Altogether, the course contributes to building a professional profile of an engineer who is technically competent and also aware of his responsibilities towards people, organisations and the broader society."
    },

    {
      "id": "physical_education",
      "titulo": "Physical Activity in Nature",
      "periodo": "1st Semester 2025-2026",
      "status": "Completed",
      "tecnologias": ["Kayak", "Archery", "Electronic shooting", "Bike"],
      "tags": ["Outdoor", "Nature", "River", "Off-road"],
      "imagens": ["assets/img/bike.jpg", "assets/img/kayak.jpg"],
      "relatorio_pdf": "",
      "descricao": "This three-day outdoor module combined physical challenge, nature immersion, and group coordination through kayaking on a river near Toulouse, archery and electronic shooting practice, and a 22 km off-road cycling route.\n\nBeyond fitness, the experience strengthened social bonds at the start of the semester and created a practical context for decision-making, safety awareness, and mutual support. Photos of the kayaking and cycling sessions are included as appendices to represent the activities completed.",
      "tecnica": "The module focused on operating safely in natural environments while adapting to changing conditions and working efficiently as a group. The kayaking day emphasized route awareness, coordination between paddlers, and fast reaction to obstacles such as small drops and unstable flows.\n\nHands-on work required using specific equipment correctly (helmet, buoyancy aid, paddle handling, and basic river navigation behaviors), as well as applying safety procedures to prevent falls and respond quickly when someone entered the water. I contributed by staying proactive in communication, keeping the group organized during critical moments, and helping ensure a rapid, calm response when assistance was needed.\n\nThe second day developed precision and focus through archery and electronic shooting, reinforcing controlled posture, attention management, and consistent execution under observation. The final cycling route demanded endurance, pacing strategy, and terrain handling, with off-road sections requiring stability, anticipation, and respect for the group’s rhythm to avoid unnecessary risks.\n\nAcross all activities, environmental responsibility was treated as part of performance: keeping personal items secured, leaving no waste behind, and preserving the natural area while moving through it.",
      "sistema_de_curso": "The course was organized as three full outdoor days, each centered on a different activity (river kayaking, archery and electronic shooting, and off-road cycling). Instruction and supervision guided safe equipment use and group behavior, and the assessment relied mainly on observed engagement, adaptation to the environment, and demonstrated safety and teamwork behaviors aligned with the competency matrix.",
      "matriz_competencia": [
        {
          "nota": 4,
          "titulo": "Take action in a natural environment: analyze, decide, act, put security in place, use specific equipment, discover an area"},
        {
          "nota": 4,
          "titulo": "Respect and adapt in an environment different from one’s normal habits"},
        {
          "nota": 4,
          "titulo": "Invest oneself coherently in activities"},
        {
          "nota": 4,
          "titulo": "Actively take part in a community"}
      ],
      "justificativa": "All four scores are consistent with how the three days were experienced in practice. On the river, fast decision-making, clear communication, and teamwork were necessary to keep the kayak stable in technical sections and to react quickly and safely when a teammate needed help. The archery and electronic shooting sessions reinforced focus, self-control, and disciplined execution, while the off-road cycling route required endurance, pacing, and careful terrain handling without losing attention to group safety.\n\nThe community dimension also deserves a top score because this module actively strengthened our cohort. Sharing challenges outdoors created trust, encouraged collaboration, and helped integrate classmates early in the semester. I engaged strongly with my colleagues throughout the activities, contributing to group motivation, coordination, and the positive atmosphere that made the experience unifying rather than just individual performance.",
      "relacao_projeto_profissional": "This module is not directly tied to a specific engineering domain, but it reinforces behaviors that transfer strongly to technical projects: teamwork under pressure, leadership by action, disciplined execution, and following safety constraints while staying goal-oriented.\n\nIn engineering environments, the same skills apply when managing risk, coordinating roles, and reacting to unexpected events without compromising the team’s stability. This experience also highlighted how community engagement improves performance: stronger bonds and communication make teams faster, safer, and more resilient during demanding work."
    }
  ]
}
